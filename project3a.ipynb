{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3a: Goals and Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals of this assignment are:\n",
    "* To analyze corpora with metadata.\n",
    "* To make some basic corpus-level visualizations.\n",
    "\n",
    "Here are the steps you should do to successfully complete this project:\n",
    "1. From moodle, accept the assignment. Open and set up a code space (install a python kernel and select it).\n",
    "2. Complete the notebook and commit it to Github. Make sure to answer all questions, and to commit the notebook in a \"run\" state!\n",
    "3. I wrote the comments; you write the code! Complete and run `spacy_on_corpus.py` following the instructions in this notebook.\n",
    "4. Edit the README.md file. Provide your name, your class year, links to/descriptions of any extensions and a list of resources. \n",
    "5. Commit your code often. We will take the last commit before the deadline as your submission of the project.\n",
    "\n",
    "Possible extensions (from least points to most points):\n",
    "* Make word counts plots for the top 100 words and entities. Look at the labels on the y axis of each plot. Where do you think spaCy is making mistakes?\n",
    "* Augment the `wordcount` functionality so that it displays relative frequencies of entity label pairs and token part of speech pairs.\n",
    "* Augment the `wordcloud' functionality so that it also makes an entity cloud.\n",
    "* Make the bar plots and/or word clouds more beautiful.\n",
    "* Learn about the useful python collections package, especially the [Counter data type](https://docs.python.org/3/library/collections.html#collections.Counter). Copy spacy_on_corpus.py and name the copy spacy_on_corpus_counter.py. Change `get_token_counts` and `get_entity_counts` to use counters. \n",
    "* Add in the analyses from project 2c as functions `make_doc_markdown`, `make_doc_tables` and `make_doc_stats`; make sure to ask the user for a document before running any of these!\n",
    "* Your other ideas are welcome! If you'd like to discuss one with Dr Stent, feel free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Our Packages\n",
    "\n",
    "On the command line (in the terminal), type:\n",
    "\n",
    "% `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Our Data\n",
    "\n",
    "From Moodle, download `files.jsonl.zip`. \n",
    "\n",
    "Then, upload `files.jsonl.zip` to the code space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Sure We Can Work With .py Files We Are Editing\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Metadata\n",
    "\n",
    "Last week we wrote functions to load and manipulate a corpus consisting of plain text files.\n",
    "\n",
    "This week we will extend that program to load and manipulate a corpus where each document also has **metadata**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Dictionaries in Files\n",
    "\n",
    "There is a format called ['JSON'](https://www.json.org/json-en.html) that looks like a python dictionary printed out. \n",
    "\n",
    "If you see a filename that has the extension `.json`, you can think of it as containing a python dictionary.\n",
    "\n",
    "If you see a filename that has the extension `.jsonl`, you can think of it as containing a python dictionary *per line*.\n",
    "\n",
    "Constellate data sets actually consiste of `.jsonl` files. Each line contains the metadata (and, if the fulltext is available, the data) for a single document. So a single file can contain all the data about a whole corpus!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file `test.jsonl` in a text editor (Visual Studio is fine) and take a look at it. How many keys does each dictionary have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a package for reading `.json` and `.jsonl` files. It is called ... `json`. We will use it from now on to read corpura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Functions in spacy_on_corpus.py\n",
    "\n",
    "For this project, you will be extending your code in `spacy_on_corpus.py`. You will fill in the functions and test them in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need a test corpus. I give you one here (the text for each document comes from the Wikipedia page for the named college or university)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "import spacy\n",
    "# import pprint\n",
    "import pprint\n",
    "\n",
    "# make a spacy engine\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# make a corpus\n",
    "corpus = {'doc1': {'text': 'Colby College is a private liberal arts college in Waterville, Maine. Founded in 1813 as the Maine Literary and Theological Institution, it was renamed Waterville College in 1821. The donations of Christian philanthropist Gardner Colby saw the institution renamed again to Colby University before settling on its current title, reflecting its liberal arts college curriculum, in 1899. Approximately 2,000 students from more than 60 countries are enrolled annually. The college offers 54 major fields of study and 30 minors. Located in central Maine, the 714-acre Neo-Georgian campus sits atop Mayflower Hill and overlooks downtown Waterville and the Kennebec River Valley. Along with fellow Maine institutions Bates College and Bowdoin College, Colby competes in the New England Small College Athletic Conference (NESCAC) and the Colby-Bates-Bowdoin Consortium.'},\n",
    "          'doc2': {'text': 'Columbia University, officially titled as Columbia University in the City of New York, is a private Ivy League research university in New York City. Established in 1754 as King\\'s College on the grounds of Trinity Church in Manhattan, it is the oldest institution of higher education in New York and the fifth-oldest in the United States.'}}\n",
    "\n",
    "# run spacy on each text in the corpus\n",
    "for key in corpus:\n",
    "    corpus[key]['doc'] = nlp(corpus[key]['text'])\n",
    "\n",
    "# print the corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `get_token_counts`\n",
    "\n",
    "Complete the implementation of `get_token_counts` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `get_token_counts` on the provided corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy_on_corpus\n",
    "\n",
    "\n",
    "# call get_token_counts on corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby', 5),\n",
    " ('College', 6),\n",
    " ('is', 3),\n",
    " ('a', 2),\n",
    " ('private', 2),\n",
    " ('liberal', 2),\n",
    " ('arts', 2),\n",
    " ('college', 3),\n",
    " ('in', 12),\n",
    " ('Waterville', 3),\n",
    " ('Maine', 4),\n",
    " ('Founded', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function has some **optional arguments**. Look at the function **signature** (the line that starts with `def`). See that there are two arguments, but one of them has a value assigned to it already (using `=`). That means, if you don't want to say what the tags to exclude should be, you can take the default ones specified in the signature. \n",
    "\n",
    "Let's try changing this. Let's make *no* tags excluded.\n",
    "\n",
    "In the code cell below, run `get_token_counts` on the corpus provided, also specifying `tags_to_exclude = []` (the empty list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_token_counts with no tags to exclude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby', 5),\n",
    " ('College', 6),\n",
    " ('is', 3),\n",
    " ('a', 2),\n",
    " ('private', 2),\n",
    " ('liberal', 2),\n",
    " ('arts', 2),\n",
    " ('college', 3),\n",
    " ('in', 12),\n",
    " ('Waterville', 3),\n",
    " (',', 9),\n",
    " ('Maine', 4),\n",
    " ('.', 9),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, referring to [the coarse-grained tag list](https://universaldependencies.org/u/pos/all.html), what do you have to do to make `get_token_counts` *only* give you counts of (proper or regular) nouns, verbs, adjectives and adverbs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_token_counts excluding all tags but those corresponding to nouns, verbs, adjectives and adverbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby', 5),\n",
    " ('College', 6),\n",
    " ('private', 2),\n",
    " ('liberal', 2),\n",
    " ('arts', 2),\n",
    " ('college', 3),\n",
    " ('Waterville', 3),\n",
    " ('Maine', 4),\n",
    " ('Founded', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `get_entity_counts`\n",
    "\n",
    "Complete the implementation of `get_entity_counts` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `get_entity_counts` on the provided corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call get_entity_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby College', 1),\n",
    " ('Waterville', 2),\n",
    " ('Maine', 3),\n",
    " ('1813', 1),\n",
    " ('the Maine Literary and Theological Institution', 1),\n",
    " ('Waterville College', 1),\n",
    " ('1821', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, referring to [the spaCy model docs](https://spacy.io/models/en), what do you have to do to make `get_entity_counts` *only* give you organizations, persons and locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_entity_counts so as to get only organizations, persons and locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby College', 1),\n",
    " ('Waterville', 2),\n",
    " ('Maine', 3),\n",
    " ('the Maine Literary and Theological Institution', 1),\n",
    " ('Waterville College', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `reduce_to_top_k`\n",
    "\n",
    "Complete the implementation of `reduce_to_top_k` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `reduce_to_top_k` on the output of `get_token_counts` on the provided corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# get the token counts on corpus; assign token_counts to the returned result\n",
    "token_counts = \n",
    "\n",
    "# call reduce_to_top_k on token_counts to get the top 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "[('of', 5), ('College', 6), ('and', 7), ('the', 11), ('in', 12)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `load_textfile`\n",
    "\n",
    "Complete the implementation of `load_textfile` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `load_textfile` on 'colby_college.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# initialize corpus to the empty dictionary\n",
    "\n",
    "# call load_textfile\n",
    "\n",
    "# print corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "{'colby_college.txt': {'doc': Colby College is a private liberal arts college in Waterville, Maine. Founded in 1813 as the Maine Literary and Theological Institution, it was renamed Waterville College in 1821. The donations of Christian philanthropist Gardner Colby saw the institution renamed again to Colby University before settling on its current title, reflecting its liberal arts college curriculum, in 1899. Approximately 2,000 students from more than 60 countries are enrolled annually. The college offers 54 major fields of study and 30 minors.\n",
    " \n",
    " Located in central Maine, the 714-acre Neo-Georgian campus sits atop Mayflower Hill and overlooks downtown Waterville and the Kennebec River Valley. Along with fellow Maine institutions Bates College and Bowdoin College, Colby competes in the New England Small College Athletic Conference (NESCAC) and the Colby-Bates-Bowdoin Consortium.\n",
    "}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `load_compressed`\n",
    "\n",
    "Complete the implementation of `load_compressed` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `load_compressed` on 'files.zip'. (This may take a little while!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# initialize corpus to the empty dictionary\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# print corpus keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "dict_keys(['temp/ark:__27927_pjb5s37cx32', 'temp/ark:__27927_phx1wcjq0tm', 'temp/ark:__27927_phzmmfj893c', 'temp/ark:__27927_phzkfzqzs41', 'temp/ark:__27927_phzq8c34ggp', 'temp/ark:__27927_pjb3ptfm8xd', 'temp/ark:__27927_phz8qhfbxzm', 'temp/ark:__27927_pjb1wn175cv', 'temp/ark:__27927_phznswfkrxz', 'temp/ark:__27927_pjb65xt4m6r', 'temp/ark:__27927_phzq26wnjzn', 'temp/ark:__27927_phzbjns29gn', 'temp/ark:__27927_phzpdcpvdnb', 'temp/ark:__27927_pjb1z8505hp', 'temp/ark:__27927_phz35174v0z', 'temp/ark:__27927_phzjj6kfdxp', 'temp/ark:__27927_pjb16g9m9r7', 'temp/ark:__27927_pjb1z5xzrx7'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `load_jsonl` (New for project 3a!)\n",
    "\n",
    "Complete the implementation of `load_jsonl` in `spacy_on_corpus.py`.\n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `load_jsonl` on `test.jsonl`. (This may take a little while!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "\n",
    "# call load_jsonl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be two entries in the resulting corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `build_corpus` (Modified for project 3a!)\n",
    "\n",
    "Complete the implementation of `build_corpus` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `build_corpus` on the pattern 'f*.jsonl.zip'. (This may take a little while!)\n",
    "\n",
    "Note, `build_corpus` _returns a corpus_, so you want to assign that return value to a variable (like `my_corpus`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call build_corpus\n",
    "\n",
    "# print corpus keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "dict_keys(['ark://27927/phz35174v0z', 'ark://27927/phzmmfj893c', 'ark://27927/pjb1wn175cv',\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at one document and its metadata. Run the code cell below to inspect the types of metadata available from Constellate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what types of metadata do each document have?\n",
    "print(my_corpus['ark://27927/pjb1z5xzrx7']['metadata'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `get_metadata_counts` (New for project 3a!)\n",
    "\n",
    "Complete the implementation of `get_metadata_counts` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `get_metadata_counts` on the provided corpus using the key 'pageCount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call get_metadata_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "[(4, 1),\n",
    " (7, 3),\n",
    " (9, 1),\n",
    " (23, 1),\n",
    " (21, 1),\n",
    " (24, 1),\n",
    " (11, 1),\n",
    " (22, 2),\n",
    " (5, 2),\n",
    " (12, 1),\n",
    " (32, 1),\n",
    " (39, 1),\n",
    " (16, 1),\n",
    " (37, 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `get_basic_statistics` (Modified for project 3a!)\n",
    "\n",
    "Complete the implementation of `get_basic_statistics` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `get_basic_statistics` on the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# call get_basic_statistics on my_corpus\n",
    "answers.get_basic_statistics(my_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look like:\n",
    "```\n",
    "Documents: 18\n",
    "\n",
    "Tokens: 170315\n",
    "\n",
    "Unique tokens: 19741\n",
    "\n",
    "Entities: 170315\n",
    "\n",
    "Unique entities: 7337\n",
    "\n",
    "Publication year range: 2015-2022\n",
    "\n",
    "Page count year range: 4-39\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `plot_word_entity_frequencies`\n",
    "\n",
    "Complete the implementation of `plot_word_entity_frequencies` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `plot_word_entity_frequencies` on the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# call plot_word_entity_frequencies on my_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting file `token_counts.png` should look like:\n",
    "\n",
    "![token_counts.png](answer_token_counts.png)\n",
    "\n",
    "The resulting file `entity_counts.png` should look like:\n",
    "\n",
    "![token_counts.png](answer_entity_counts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `plot_word_cloud`\n",
    "\n",
    "Complete the implementation of `plot_word_cloud` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `plot_word_cloud` on the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# call plot_word_cloud on my_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting file `token_counts.png` should look like:\n",
    "\n",
    "![token_wordcloud.png](answer_token_wordcloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Wordcount and Wordcloud Plots Informative\n",
    "\n",
    "Modify `plot_word_entity_frequencies` and `plot_word_cloud` functions so they produce *informative* plots (excluding function words like *and* and *a*, punctuation, and numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `plot_metadata_frequencies` (New for project 3a!)\n",
    "\n",
    "Complete the implementation of `plot_metadata_frequencies` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `plot_metadata_frequencies` on the given corpus using the key 'publicationYear'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# call plot_metadata_frequencies on my_corpus to get the publicationYear frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting file `publicationYear_counts.png` should look like:\n",
    "\n",
    "![pubYear_counts.png](publicationYear_counts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running `spacy_on_corpus.py` from the Terminal (Modified for project 3a!)\n",
    "\n",
    "Complete the implementation of `main` in `spacy_on_corpus.py`. \n",
    "\n",
    "Now run this in the terminal:\n",
    "% `python spacy_on_corpus.py`\n",
    "\n",
    "Give it `files.jsonl.zip` as the pattern. Get all of 'statistics', 'wordcount' and 'wordcloud' as well as bar charts for 'publicationYear' and 'pageCount'.\n",
    "\n",
    "Insert the images generated when you run it.\n",
    "\n",
    "## Token count plot\n",
    "\n",
    "\n",
    "## Entity count plot\n",
    "\n",
    "\n",
    "## Word cloud\n",
    "\n",
    "\n",
    "## Publication year plot\n",
    "\n",
    "\n",
    "# Page count plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer these questions with respect to the corpus defined by `files.jsonl.zip`.\n",
    "\n",
    "1. *How many tokens and unique tokens are in this corpus?*\n",
    "2. *What is the average number of pages of documents in this corpus?*\n",
    "3. *What is the most frequent year in which articles in this corpus were published?* \n",
    "4. *What happens when you try to get metadata counts for the metadata key `tdmCategory`? Why?*\n",
    "5. *What is the structure of the return value from `get_metadata_counts`?*\n",
    "6. *What does the function `loads()` in the package `json` do? Is it more suited to `.json` or `.jsonl` files?\n",
    "7. *Name and describe one function in the package `json` other than `loads()`.*\n",
    "8. *List three metadata keys in this corpus:* \n",
    "9. *One of the metadata keys in this corpus is 'doi'. What is a DOI?*\n",
    "10. *Could we get a good understanding of the themes of this corpus just from the metadata (not the fulltext)? Why or why not?*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
